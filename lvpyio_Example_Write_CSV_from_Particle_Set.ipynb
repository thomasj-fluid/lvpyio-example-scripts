{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb09bb9",
   "metadata": {},
   "source": [
    "# Write CSV files from Particle sets\n",
    "This notebook suggest a way of how to create CSV formatted files containing the particle track information originating from a **DaVis** particle set using **lvpyio**. In addition to the raw particle positions, the velocities are calculated and exported as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63d02516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import lvpyio as lv\n",
    "from csaps import CubicSmoothingSpline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e1409b",
   "metadata": {},
   "source": [
    "## Define function to calculate particle velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4e5be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a function, which fits a single trajectory with a smoothing cubic spline. \n",
    "# Based on this spline, the first and second derivatives of the trajectories can be calculated.\n",
    "# The first derivated is used to calculate the particle's velocity.\n",
    "# Additionally the local curvature of the trajectory is calculated using both the first and second derivative.\n",
    "\n",
    "def f_calc_velocity(track,dt,scaling, smooth_val):\n",
    "\n",
    "    # get coordinates and rescale to meters\n",
    "    x_raw = (track.particles[:]['x']*scaling.x.slope+scaling.x.offset)/1000\n",
    "    y_raw = (track.particles[:]['y']*scaling.y.slope+scaling.y.offset)/1000\n",
    "    z_raw = (track.particles[:]['z']*scaling.z.slope+scaling.z.offset)/1000\n",
    "    \n",
    "    # get track length\n",
    "    length_track = np.size(x_raw)\n",
    "    \n",
    "    # Create arbitrary time vector. Absolute values not necessary here, only the spacing with dt\n",
    "    t_raw=np.linspace(-length_track/2,length_track/2,length_track)*dt # create time vector for filter window\n",
    "    \n",
    "    # Fit x-data with Smoothing spline\n",
    "    s = CubicSmoothingSpline(t_raw, x_raw, smooth=smooth_val, normalizedsmooth=True).spline\n",
    "    # Calculate derivatives\n",
    "    dx1 = s.derivative(nu=1)\n",
    "    dx2 = s.derivative(nu=2)\n",
    "    # Save velocity\n",
    "    U = dx1(t_raw)\n",
    "    \n",
    "    # Fit y-data with Smoothing spline\n",
    "    s = CubicSmoothingSpline(t_raw, y_raw, smooth=smooth_val, normalizedsmooth=True).spline\n",
    "    # Calculate derivatives\n",
    "    dy1 = s.derivative(nu=1)\n",
    "    dy2 = s.derivative(nu=2)\n",
    "    # Save velocity\n",
    "    V = dy1(t_raw)\n",
    "    \n",
    "    # Fit z-data with Smoothing spline\n",
    "    s = CubicSmoothingSpline(t_raw, z_raw, smooth=smooth_val, normalizedsmooth=True).spline\n",
    "    # Calculate derivatives\n",
    "    dz1 = s.derivative(nu=1)\n",
    "    dz2 = s.derivative(nu=2)\n",
    "    # Save velocity\n",
    "    W = dz1(t_raw)\n",
    "    \n",
    "    return U, V, W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780879d0",
   "metadata": {},
   "source": [
    "## Read particle data and add velocity information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43dab80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DaVis particle set\n",
    "tracks_lv = lv.read_particles('data\\\\Tracks_Cylinder_Wake')\n",
    "\n",
    "dt = tracks_lv.times()[1]-tracks_lv.times()[0] # retrieve dt of measurements\n",
    "\n",
    "# initialize new list, which will contain the tracks with the added scalars\n",
    "tracks_export = list()\n",
    "\n",
    "# read scaling of positional data\n",
    "scaling = tracks_lv.scales\n",
    "\n",
    "# define scales of new scalars\n",
    "scalar_scales = {\"U\": lv.Scale(1, 0, \"m/s\", \"Spline velocity u\"),\"V\": lv.Scale(1, 0, \"m/s\", \"Spline velocity v\"),\"W\": lv.Scale(1, 0, \"m/s\", \"Spline velocity w\")}\n",
    "\n",
    "for ii in range(tracks_lv.track_count): # loop over all trajectories\n",
    "\n",
    "    track_temp = tracks_lv.single_track(ii) # get trajectory information\n",
    "    U, V, W = f_calc_velocity(track_temp,dt,scaling, 0.85) # calculate new scalars\n",
    "    track_temp.scalars = {\"U\": U,\"V\": V,\"W\": W} # add scalars to track object\n",
    "    \n",
    "    tracks_export.append(track_temp) # add track to export list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4eee97",
   "metadata": {},
   "source": [
    "## CSV Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e8c0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting time-step: t000.txt\n",
      "Exporting time-step: t001.txt\n",
      "Exporting time-step: t002.txt\n",
      "Exporting time-step: t003.txt\n",
      "Exporting time-step: t004.txt\n",
      "Exporting time-step: t005.txt\n",
      "Exporting time-step: t006.txt\n",
      "Exporting time-step: t007.txt\n",
      "Exporting time-step: t008.txt\n",
      "Exporting time-step: t009.txt\n",
      "Exporting time-step: t010.txt\n",
      "Exporting time-step: t011.txt\n",
      "Exporting time-step: t012.txt\n",
      "Exporting time-step: t013.txt\n",
      "Exporting time-step: t014.txt\n",
      "Exporting time-step: t015.txt\n",
      "Exporting time-step: t016.txt\n",
      "Exporting time-step: t017.txt\n",
      "Exporting time-step: t018.txt\n",
      "Exporting time-step: t019.txt\n",
      "Exporting time-step: t020.txt\n",
      "Exporting time-step: t021.txt\n",
      "Exporting time-step: t022.txt\n",
      "Exporting time-step: t023.txt\n",
      "Exporting time-step: t024.txt\n",
      "Exporting time-step: t025.txt\n",
      "Exporting time-step: t026.txt\n",
      "Exporting time-step: t027.txt\n",
      "Exporting time-step: t028.txt\n",
      "Exporting time-step: t029.txt\n",
      "Exporting time-step: t030.txt\n",
      "Exporting time-step: t031.txt\n",
      "Exporting time-step: t032.txt\n",
      "Exporting time-step: t033.txt\n",
      "Exporting time-step: t034.txt\n",
      "Exporting time-step: t035.txt\n",
      "Exporting time-step: t036.txt\n",
      "Exporting time-step: t037.txt\n",
      "Exporting time-step: t038.txt\n",
      "Exporting time-step: t039.txt\n",
      "Exporting time-step: t040.txt\n",
      "Exporting time-step: t041.txt\n",
      "Exporting time-step: t042.txt\n",
      "Exporting time-step: t043.txt\n",
      "Exporting time-step: t044.txt\n",
      "Exporting time-step: t045.txt\n",
      "Exporting time-step: t046.txt\n",
      "Exporting time-step: t047.txt\n",
      "Exporting time-step: t048.txt\n",
      "Exporting time-step: t049.txt\n",
      "Exporting time-step: t050.txt\n",
      "Exporting time-step: t051.txt\n",
      "Exporting time-step: t052.txt\n",
      "Exporting time-step: t053.txt\n",
      "Exporting time-step: t054.txt\n",
      "Exporting time-step: t055.txt\n",
      "Exporting time-step: t056.txt\n",
      "Exporting time-step: t057.txt\n",
      "Exporting time-step: t058.txt\n",
      "Exporting time-step: t059.txt\n",
      "Exporting time-step: t060.txt\n",
      "Exporting time-step: t061.txt\n",
      "Exporting time-step: t062.txt\n",
      "Exporting time-step: t063.txt\n",
      "Exporting time-step: t064.txt\n",
      "Exporting time-step: t065.txt\n",
      "Exporting time-step: t066.txt\n",
      "Exporting time-step: t067.txt\n",
      "Exporting time-step: t068.txt\n",
      "Exporting time-step: t069.txt\n",
      "Exporting time-step: t070.txt\n",
      "Exporting time-step: t071.txt\n",
      "Exporting time-step: t072.txt\n",
      "Exporting time-step: t073.txt\n",
      "Exporting time-step: t074.txt\n",
      "Exporting time-step: t075.txt\n",
      "Exporting time-step: t076.txt\n",
      "Exporting time-step: t077.txt\n",
      "Exporting time-step: t078.txt\n",
      "Exporting time-step: t079.txt\n",
      "Exporting time-step: t080.txt\n",
      "Exporting time-step: t081.txt\n",
      "Exporting time-step: t082.txt\n",
      "Exporting time-step: t083.txt\n",
      "Exporting time-step: t084.txt\n",
      "Exporting time-step: t085.txt\n",
      "Exporting time-step: t086.txt\n",
      "Exporting time-step: t087.txt\n",
      "Exporting time-step: t088.txt\n",
      "Exporting time-step: t089.txt\n",
      "Exporting time-step: t090.txt\n",
      "Exporting time-step: t091.txt\n",
      "Exporting time-step: t092.txt\n",
      "Exporting time-step: t093.txt\n",
      "Exporting time-step: t094.txt\n",
      "Exporting time-step: t095.txt\n",
      "Exporting time-step: t096.txt\n",
      "Exporting time-step: t097.txt\n",
      "Exporting time-step: t098.txt\n",
      "Exporting time-step: t099.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check for output folder\n",
    "import os\n",
    "try:\n",
    "    os.makedirs(\"data\\\\ExportCSV\\\\\")\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "# Specify column formatting for file export\n",
    "# X Y Z U V W trackID\n",
    "fmt = '%1.4f', '%1.4f', '%1.4f', '%1.4f', '%1.4f', '%1.4f', '%d'\n",
    "\n",
    "for t in range(np.size(tracks_lv.times())): # loop over all time steps in order to create a single file per time step\n",
    "    kk = 0\n",
    "    \n",
    "    for ii in range(np.size(tracks_export)): # loop over all trajectories\n",
    "        \n",
    "        # check if particle exists in the desired time step\n",
    "        if (t >= tracks_export[ii].start) & (t < tracks_export[ii].start + np.size(tracks_export[ii].particles)):\n",
    "            trackID = ii\n",
    "            t_track = t-tracks_export[ii].start\n",
    "            data_csv_temp = tracks_export[ii].particles[\"x\"][t_track]*scaling.x.slope+scaling.x.offset # set first columns\n",
    "            data_csv_temp = np.c_[data_csv_temp,tracks_export[ii].particles[\"y\"][t_track]*scaling.y.slope+scaling.y.offset,\n",
    "                                  tracks_export[ii].particles[\"z\"][t_track]*scaling.z.slope+scaling.z.offset,\n",
    "                                  tracks_export[ii].scalars[\"U\"][t_track],\n",
    "                                  tracks_export[ii].scalars[\"V\"][t_track],\n",
    "                                  tracks_export[ii].scalars[\"W\"][t_track],\n",
    "                                  trackID] # append other columns\n",
    "\n",
    "            # write data array, which will then be exported\n",
    "            if kk==0:\n",
    "                data_csv = data_csv_temp\n",
    "            else:\n",
    "                data_csv = np.vstack([data_csv,data_csv_temp])\n",
    "                \n",
    "            kk = kk+1\n",
    "      \n",
    "    # save file \n",
    "    file_specifier = str(int(t)).zfill(3) # define leading zeros in file name   \n",
    "    print(\"Exporting time-step: t\" + file_specifier + \".txt\")  \n",
    "    np.savetxt(\"data\\\\ExportCSV\\\\ParticleData_t\" + file_specifier + \".txt\", data_csv, delimiter=\" \", header='X[mm] Y[mm] Z[mm] U[m/s] V[m/s] W[m/s] trackID', fmt=fmt, comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
